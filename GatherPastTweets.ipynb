{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import string \n",
    "\n",
    "import time\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "auth = tweepy.AppAuthHandler(\"0q42FevFlZHyuxHyewTT3jEgf\", \"kzq6n4xQKv3a0tNRNhSAN7cm6nwUyjqpiEobkyF39hMcT3VhCj\")\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to clean tweet gather from twitter\n",
    "def preprocessign(text):\n",
    "    #Remove url from tweets\n",
    "    text= \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", text).split())\n",
    "    #Remove emoji from tweet\n",
    "    text=text.encode('ascii', 'ignore').decode('ascii')\n",
    "    #convert tweet in lower case\n",
    "    text = text.lower()\n",
    "    #remove some special symobol\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #remove puncutation mark\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #remove word with digit\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for this hashtage . You can write according requirement. You search any thing you want\n",
    "searchQuery = \"#COVID19 OR #lockdown OR #coronavirus OR #CoronavirusPandemic OR #covid_19\"+ \" -filter:retweets\"   # this is what we're searching for\n",
    "#maximum tweet you want to fetch\n",
    "maxTweets = 10000000 \n",
    "# this is the max the API permits\n",
    "tweetsPerQry = 100  \n",
    "#max limit of tweet unique id\n",
    "max_id = -1\n",
    "#fetched tweet count\n",
    "tweetCount = 0\n",
    "#min limit of tweet unique id\n",
    "sinceId = 1282641096711958528\n",
    "#heading of csv file\n",
    "Heading=[\"Tweet_id\",\"Tweet_date\",\"Tweet_text\",\"polarity\",\"subjectivity\",\"user_location\",\"longitude\",\"latitude\",\"hashtags\"]\n",
    "i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Tweets....\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "some error : Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out.\n",
      "Tweets save in filename.csv\n",
      "1283006762392653827\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#open file to write data\n",
    "with open('new.csv', 'a', newline='',encoding=\"utf-8\") as file:\n",
    "    print(\"Reading Tweets....\")\n",
    "    #create object of writter\n",
    "    writer = csv.writer(file)\n",
    "    #write heading into file\n",
    "    writer.writerow(Heading)\n",
    "    #repeat untill tweetcount is less then maxtweet count\n",
    "    while tweetCount < maxTweets:\n",
    "            try:\n",
    "                if (max_id <= 0):\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,tweet_mode=\"extended\",lang=\"en\")\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                since_id=sinceId,tweet_mode=\"extended\",lang=\"en\")\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1),tweet_mode=\"extended\",lang=\"en\")\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1),\n",
    "                                                since_id=sinceId,tweet_mode=\"extended\",lang=\"en\")\n",
    "                if not new_tweets:\n",
    "                    print(\"No more tweets found\")\n",
    "                    break\n",
    "                for tweet in new_tweets:\n",
    "                    print(i)\n",
    "                    i+=1\n",
    "                    text=preprocessign(tweet.full_text)\n",
    "                    user_location = preprocessign(tweet.user.location)\n",
    "                    if tweet.place:\n",
    "                        user_location=tweet.place.country.lower();\n",
    "                    if type(user_location) == str:\n",
    "                        user_location=preprocessign(user_location)\n",
    "                    longitude = None\n",
    "                    latitude = None\n",
    "                    hashtag=[i['text'].lower() for i in tweet.entities['hashtags']]\n",
    "                    if tweet.coordinates:\n",
    "                        longitude = tweet.coordinates['coordinates'][0]\n",
    "                        latitude = tweet.coordinates['coordinates'][1]\n",
    "                    sentiment = TextBlob(text).sentiment\n",
    "                    writer.writerow([tweet.id_str,tweet.created_at,text,sentiment.polarity,sentiment.subjectivity,user_location,longitude,latitude,hashtag])\n",
    "                tweetCount += len(new_tweets)\n",
    "                max_id = new_tweets[-1].id\n",
    "            except tweepy.TweepError as e:\n",
    "                # Just exit if any error\n",
    "                print(\"some error : \" + str(e))\n",
    "                break\n",
    "print(\"Tweets save in filename.csv\")\n",
    "print(max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets=pd.read_csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Tweet_date</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>user_location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1283008340679852033</td>\n",
       "      <td>2020-07-14 12:00:00</td>\n",
       "      <td>a key difference between sydney and melbournes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['covid19']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1283008340642144257</td>\n",
       "      <td>2020-07-14 12:00:00</td>\n",
       "      <td>people often underestimate those living with d...</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.451515</td>\n",
       "      <td>nottingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['lockdown']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1283008339430068224</td>\n",
       "      <td>2020-07-14 11:59:59</td>\n",
       "      <td>what is it exactly about wearing a face mask t...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>south east by the sea england</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['facemask', 'facemasks', 'covid19', 'coronavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1283008338305916928</td>\n",
       "      <td>2020-07-14 11:59:59</td>\n",
       "      <td>garen staglin coauthors forbes blogpost stress...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>park avenue floornew york ny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['diversity', 'covid19', 'mentalhealth', 'lgbt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1283008337341296640</td>\n",
       "      <td>2020-07-14 11:59:59</td>\n",
       "      <td>there is growing evidence that airpollution co...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['airpollution', 'covid19', 'iaq']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1283006766398214147</td>\n",
       "      <td>2020-07-14 11:53:44</td>\n",
       "      <td>truth is out there</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ecuador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['budesonida', 'budesonide', 'silverbullet', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1283006765735350272</td>\n",
       "      <td>2020-07-14 11:53:44</td>\n",
       "      <td>experts call for australia to replace coronavi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>offices melbourne canberra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['experts', 'australia', 'coronavirus', 'strat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1283006764129021952</td>\n",
       "      <td>2020-07-14 11:53:44</td>\n",
       "      <td>calcutta hc orders postmortem of an  boy who h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>india</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['calcutta', 'covid19']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1283006762413481985</td>\n",
       "      <td>2020-07-14 11:53:43</td>\n",
       "      <td>its not jst some important people getting coro...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>india</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['corona', 'biharfightscorona', 'covid_19', 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1283006762392653827</td>\n",
       "      <td>2020-07-14 11:53:43</td>\n",
       "      <td>help slow the spread of  and identify at risk ...</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>bristol england</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['covid19']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tweet_id           Tweet_date  \\\n",
       "0    1283008340679852033  2020-07-14 12:00:00   \n",
       "1    1283008340642144257  2020-07-14 12:00:00   \n",
       "2    1283008339430068224  2020-07-14 11:59:59   \n",
       "3    1283008338305916928  2020-07-14 11:59:59   \n",
       "4    1283008337341296640  2020-07-14 11:59:59   \n",
       "..                   ...                  ...   \n",
       "495  1283006766398214147  2020-07-14 11:53:44   \n",
       "496  1283006765735350272  2020-07-14 11:53:44   \n",
       "497  1283006764129021952  2020-07-14 11:53:44   \n",
       "498  1283006762413481985  2020-07-14 11:53:43   \n",
       "499  1283006762392653827  2020-07-14 11:53:43   \n",
       "\n",
       "                                            Tweet_text  polarity  \\\n",
       "0    a key difference between sydney and melbournes...  0.000000   \n",
       "1    people often underestimate those living with d...  0.245455   \n",
       "2    what is it exactly about wearing a face mask t...  0.250000   \n",
       "3    garen staglin coauthors forbes blogpost stress...  0.000000   \n",
       "4    there is growing evidence that airpollution co...  0.250000   \n",
       "..                                                 ...       ...   \n",
       "495                                truth is out there   0.000000   \n",
       "496  experts call for australia to replace coronavi...  0.000000   \n",
       "497  calcutta hc orders postmortem of an  boy who h...  0.000000   \n",
       "498  its not jst some important people getting coro...  0.433333   \n",
       "499  help slow the spread of  and identify at risk ... -0.150000   \n",
       "\n",
       "     subjectivity                  user_location  longitude  latitude  \\\n",
       "0        0.875000                      australia        NaN       NaN   \n",
       "1        0.451515                     nottingham        NaN       NaN   \n",
       "2        0.250000  south east by the sea england        NaN       NaN   \n",
       "3        0.000000   park avenue floornew york ny        NaN       NaN   \n",
       "4        0.250000                             uk        NaN       NaN   \n",
       "..            ...                            ...        ...       ...   \n",
       "495      0.000000                        ecuador        NaN       NaN   \n",
       "496      0.000000     offices melbourne canberra        NaN       NaN   \n",
       "497      0.022222                          india        NaN       NaN   \n",
       "498      0.833333                          india        NaN       NaN   \n",
       "499      0.200000                bristol england        NaN       NaN   \n",
       "\n",
       "                                              hashtags  \n",
       "0                                          ['covid19']  \n",
       "1                                         ['lockdown']  \n",
       "2    ['facemask', 'facemasks', 'covid19', 'coronavi...  \n",
       "3    ['diversity', 'covid19', 'mentalhealth', 'lgbt...  \n",
       "4                   ['airpollution', 'covid19', 'iaq']  \n",
       "..                                                 ...  \n",
       "495  ['budesonida', 'budesonide', 'silverbullet', '...  \n",
       "496  ['experts', 'australia', 'coronavirus', 'strat...  \n",
       "497                            ['calcutta', 'covid19']  \n",
       "498  ['corona', 'biharfightscorona', 'covid_19', 'i...  \n",
       "499                                        ['covid19']  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
